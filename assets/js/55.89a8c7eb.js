(window.webpackJsonp=window.webpackJsonp||[]).push([[55],{1607:function(t,s,n){"use strict";n.r(s);var a=n(0),o=Object(a.a)({},function(){this.$createElement;this._self._c;return this._m(0)},[function(){var t=this,s=t.$createElement,n=t._self._c||s;return n("div",{staticClass:"content"},[n("h1",{attrs:{id:"虚拟dom基础api"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#虚拟dom基础api","aria-hidden":"true"}},[t._v("#")]),t._v(" 虚拟DOM基础API")]),n("ul",[n("li",[t._v("基于 JSX 表达虚拟 DOM")]),n("li",[t._v("绑定虚拟 DOM 到真实 DOM")]),n("li",[t._v("虚拟 DOM 更新算法")])]),n("h2",{attrs:{id:"表达虚拟-dom"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#表达虚拟-dom","aria-hidden":"true"}},[t._v("#")]),t._v(" 表达虚拟 DOM")]),n("p",[t._v("实际上我们所编写的 JSX 的标签，都会创建一个 React.createElement 的函数，在我们考虑如何实现自己的虚拟DOM时候，我们就要考虑怎么实现一个我们自己的函数。使用自己的 dom 函数，把 React.createElement 替代。这时候我们就要考量，这个函数的输入是什么，输出应该是什么？")]),n("ul",[n("li",[t._v("如何实现替代 React.createElement 的 dom 函数？")]),n("li",[t._v("函数输入？")]),n("li",[t._v("函数输出？")])]),n("p",[t._v("在一个 DOM 元素中的表现结构,主要由标签、参数、子元素 组成。")]),n("pre",{pre:!0,attrs:{class:"language-html"}},[n("code",[n("span",{attrs:{class:"token tag"}},[n("span",{attrs:{class:"token tag"}},[n("span",{attrs:{class:"token punctuation"}},[t._v("<")]),t._v("div")]),n("span",{attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n  "),n("span",{attrs:{class:"token tag"}},[n("span",{attrs:{class:"token tag"}},[n("span",{attrs:{class:"token punctuation"}},[t._v("<")]),t._v("span")]),n("span",{attrs:{class:"token punctuation"}},[t._v(">")])]),n("span",{attrs:{class:"token tag"}},[n("span",{attrs:{class:"token tag"}},[n("span",{attrs:{class:"token punctuation"}},[t._v("</")]),t._v("span")]),n("span",{attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n  "),n("span",{attrs:{class:"token tag"}},[n("span",{attrs:{class:"token tag"}},[n("span",{attrs:{class:"token punctuation"}},[t._v("<")]),t._v("span")]),n("span",{attrs:{class:"token punctuation"}},[t._v(">")])]),n("span",{attrs:{class:"token tag"}},[n("span",{attrs:{class:"token tag"}},[n("span",{attrs:{class:"token punctuation"}},[t._v("</")]),t._v("span")]),n("span",{attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),n("span",{attrs:{class:"token tag"}},[n("span",{attrs:{class:"token tag"}},[n("span",{attrs:{class:"token punctuation"}},[t._v("</")]),t._v("div")]),n("span",{attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])]),n("p",[t._v("因此，我们转化还书的输入参数主要为： 标签、参数、子结构。")]),n("ul",[n("li",[t._v("type 标签名")]),n("li",[t._v("porps 各种属性 class/style/width/height ...")]),n("li",[t._v("children 子结构数组")])]),n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{attrs:{class:"token function"}},[t._v("dom")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("type"),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" props"),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{attrs:{class:"token operator"}},[t._v("...")]),t._v("children"),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" type"),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" props"),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" children "),n("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),n("p",[t._v("这时候我们的函数的输出，是一个有对应关系的 JSON 树结构。")]),n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" \n  type"),n("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{attrs:{class:"token string"}},[t._v("'div'")]),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  props"),n("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{attrs:{class:"token keyword"}},[t._v("null")]),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  children"),n("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" \n   "),n("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" type"),n("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{attrs:{class:"token string"}},[t._v("'span'")]),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" props"),n("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{attrs:{class:"token keyword"}},[t._v("null")]),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" children"),n("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Object"),n("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n     "),n("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" type"),n("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{attrs:{class:"token string"}},[t._v("'span'")]),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" props"),n("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{attrs:{class:"token keyword"}},[t._v("null")]),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" children"),n("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Object"),n("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" \n"),n("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),n("p",[t._v("尝试使用一下")]),n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{attrs:{class:"token function"}},[t._v("dom")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("type"),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" props"),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{attrs:{class:"token operator"}},[t._v("...")]),t._v("children"),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" type"),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" props"),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" children "),n("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{attrs:{class:"token keyword"}},[t._v("const")]),t._v(" vdom "),n("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{attrs:{class:"token function"}},[t._v("dom")]),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  "),n("span",{attrs:{class:"token string"}},[t._v("'div'")]),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),n("span",{attrs:{class:"token keyword"}},[t._v("null")]),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),n("span",{attrs:{class:"token function"}},[t._v("dom")]),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{attrs:{class:"token string"}},[t._v("'span'")]),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{attrs:{class:"token keyword"}},[t._v("null")]),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{attrs:{class:"token string"}},[t._v("'123'")]),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),n("span",{attrs:{class:"token function"}},[t._v("dom")]),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{attrs:{class:"token string"}},[t._v("'span'")]),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{attrs:{class:"token keyword"}},[t._v("null")]),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{attrs:{class:"token string"}},[t._v("'456'")]),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nconsole"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{attrs:{class:"token function"}},[t._v("log")]),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("vdom"),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),n("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{attrs:{class:"token string"}},[t._v('"type"')]),n("span",{attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{attrs:{class:"token string"}},[t._v('"div"')]),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),n("span",{attrs:{class:"token string"}},[t._v('"props"')]),n("span",{attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{attrs:{class:"token keyword"}},[t._v("null")]),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),n("span",{attrs:{class:"token string"}},[t._v('"children"')]),n("span",{attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{attrs:{class:"token string"}},[t._v('"type"')]),n("span",{attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{attrs:{class:"token string"}},[t._v('"span"')]),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{attrs:{class:"token string"}},[t._v('"props"')]),n("span",{attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{attrs:{class:"token keyword"}},[t._v("null")]),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{attrs:{class:"token string"}},[t._v('"children"')]),n("span",{attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{attrs:{class:"token string"}},[t._v('"123"')]),n("span",{attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),n("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{attrs:{class:"token string"}},[t._v('"type"')]),n("span",{attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{attrs:{class:"token string"}},[t._v('"span"')]),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{attrs:{class:"token string"}},[t._v('"props"')]),n("span",{attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{attrs:{class:"token keyword"}},[t._v("null")]),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{attrs:{class:"token string"}},[t._v('"children"')]),n("span",{attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{attrs:{class:"token string"}},[t._v('"456"')]),n("span",{attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),n("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),n("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),n("h2",{attrs:{id:"绑定真实-dom"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#绑定真实-dom","aria-hidden":"true"}},[t._v("#")]),t._v(" 绑定真实 DOM")]),n("p",[t._v("接下来我们要考虑的是，我们已经拿到了 JSON 结构，通过调用 DOM 的 API 操作，渲染到真实的 DOM 上去。核心在于调用真实 DOM 的 API，比如说 "),n("strong",[t._v("document.createElement")]),t._v(" 、"),n("strong",[t._v("document.createTextNode")]),t._v(" ，把 JSON 结构变成真实 DOM。")]),n("p",[t._v("这时候我们就要设计一个函数，实现这个功能。")]),n("ol",[n("li",[t._v("输入一个虚拟 DOM 节点，返回对应的真实 DOM 节点")]),n("li",[t._v("节点内容为纯文本时，表示节点该节点为叶子节点")]),n("li",[t._v("节点内容为非叶子节点时，递归对所有子节点调用本函数")])]),n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{attrs:{class:"token comment"}},[t._v("// 输入一个虚拟 DOM 节点，返回对应的真实 DOM 节点")]),t._v("\n"),n("span",{attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{attrs:{class:"token function"}},[t._v("createElement")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{attrs:{class:"token comment"}},[t._v("// 节点内容为纯文本时，表示节点该节点为叶子节点")]),t._v("\n  "),n("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{attrs:{class:"token keyword"}},[t._v("typeof")]),t._v(" node "),n("span",{attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),n("span",{attrs:{class:"token string"}},[t._v("'string'")]),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" document"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{attrs:{class:"token function"}},[t._v("createTextNode")]),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),n("span",{attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{attrs:{class:"token comment"}},[t._v("// 节点内容为非叶子节点时，递归对所有子节点调用本函数")]),t._v("\n    "),n("span",{attrs:{class:"token keyword"}},[t._v("const")]),t._v(" $el "),n("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" document"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{attrs:{class:"token function"}},[t._v("createElement")]),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type"),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    node"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("children\n      "),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{attrs:{class:"token function"}},[t._v("map")]),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("createElement"),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{attrs:{class:"token function"}},[t._v("forEach")]),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("$el"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("appendChild"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{attrs:{class:"token function"}},[t._v("bind")]),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("$el"),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" $el\n  "),n("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),n("h2",{attrs:{id:"虚拟-dom-更新算法"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#虚拟-dom-更新算法","aria-hidden":"true"}},[t._v("#")]),t._v(" 虚拟 DOM 更新算法")]),n("p",[t._v("接下来我们要思考虚拟DOM的跟新算法，我们可以把这个算法封装成一个函数 "),n("strong",[t._v("updateElement")]),t._v("。我们在进行一些全量的 render 的时候，会把完全全新的数据模型结构丢给框架。这时候，我们就会调用函数 "),n("strong",[t._v("updateElement")]),t._v("，对 DOM 进行差量的更新。因此这个函数的输入是两个虚拟DOM，用于对比，在对比过程中需要发现哪些节点发生改变，然后对改变的节点调用真实DOM操作，把改变了的节点进行更新，没有改变的节点继续保留。这个时候或许我们还需要一个辅助函数 函数 "),n("strong",[t._v("isChanged")]),t._v(" ，这个函数用于比较两个虚拟DOM的元素是否相等。函数 "),n("strong",[t._v("isChanged")]),t._v(" 输入应该为两个比较的元素，输出 true/false 。")]),n("ol",[n("li",[t._v("比较节点是否改变的 isChanged 函数")]),n("li",[t._v("输入 DOM 与新旧节点，执行更新的 updateElement 函数")]),n("li",[t._v("使用 updateElement 来差量更新 DOM")])]),n("ul",[n("li",[t._v("updateElement 函数\n"),n("ul",[n("li",[t._v("函数输入？")]),n("li",[t._v("函数输出？")])])]),n("li",[t._v("isChanged 函数\n"),n("ul",[n("li",[t._v("函数输入？")]),n("li",[t._v("函数输出？")])])])]),n("h3",{attrs:{id:"updateelement-设计"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#updateelement-设计","aria-hidden":"true"}},[t._v("#")]),t._v(" updateElement 设计")]),n("ul",[n("li",[t._v("输入 $parent / newNode / oldNode / index\n"),n("ul",[n("li",[t._v("$parent 父节点")]),n("li",[t._v("newNode 新的虚拟DOM的JSON树")]),n("li",[t._v("oldNode 原来的虚拟DOM的JSON树")]),n("li",[t._v("index   用来指名当前更新到第几个标")])])]),n("li",[t._v("根据 Diff 结果，更新 $parent 并递归向下")]),n("li",[t._v("递归过程中，通过副作用按需更新 DOM，无显式输出")])]),n("h3",{attrs:{id:"diff-可能情形"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#diff-可能情形","aria-hidden":"true"}},[t._v("#")]),t._v(" Diff 可能情形")]),n("p",[t._v("在 updateElement 过程中，会遇到哪些情形")]),n("ul",[n("li",[t._v("不存在旧节点")]),n("li",[t._v("不存在新节点")]),n("li",[t._v("新旧节点均存在\n"),n("ul",[n("li",[t._v("节点状态未改变")]),n("li",[t._v("节点状态改变")])])])]),n("h4",{attrs:{id:"不存在旧节点"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#不存在旧节点","aria-hidden":"true"}},[t._v("#")]),t._v(" 不存在旧节点")]),n("p",[t._v("直接把新节点插入真实DOM")]),n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{attrs:{class:"token function"}},[t._v("updateElement")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("$parent"),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" newNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" oldNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" index "),n("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{attrs:{class:"token number"}},[t._v("0")]),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{attrs:{class:"token comment"}},[t._v("// 不存在旧节点")]),t._v("\n  "),n("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{attrs:{class:"token operator"}},[t._v("!")]),t._v("oldNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    $parent"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{attrs:{class:"token function"}},[t._v("appendChild")]),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      "),n("span",{attrs:{class:"token function"}},[t._v("createElement")]),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),n("h4",{attrs:{id:"不存在新节点"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#不存在新节点","aria-hidden":"true"}},[t._v("#")]),t._v(" 不存在新节点")]),n("p",[t._v("直接把旧节点从真实DOM移除")]),n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{attrs:{class:"token function"}},[t._v("updateElement")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("$parent"),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" newNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" oldNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" index "),n("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{attrs:{class:"token number"}},[t._v("0")]),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{attrs:{class:"token operator"}},[t._v("!")]),t._v("oldNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    $parent"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{attrs:{class:"token function"}},[t._v("appendChild")]),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      "),n("span",{attrs:{class:"token function"}},[t._v("createElement")]),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{attrs:{class:"token comment"}},[t._v("// 不存在新节点")]),t._v("\n  "),n("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),n("span",{attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),n("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{attrs:{class:"token operator"}},[t._v("!")]),t._v("newNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    $parent"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{attrs:{class:"token function"}},[t._v("removeChild")]),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      $parent"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("childNodes"),n("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("index"),n("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),n("h4",{attrs:{id:"新旧节点均存在，但节点类型发生改变"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#新旧节点均存在，但节点类型发生改变","aria-hidden":"true"}},[t._v("#")]),t._v(" 新旧节点均存在，但节点类型发生改变")]),n("p",[t._v("例如一个原来 div 标签 突然变成了 p 标签，这时候我们通过 replaceChild 把原有的节点通过 createElement 创建的新节点。")]),n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{attrs:{class:"token function"}},[t._v("updateElement")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("$parent"),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" newNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" oldNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" index "),n("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{attrs:{class:"token number"}},[t._v("0")]),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{attrs:{class:"token comment"}},[t._v("// …")]),t._v("\n  "),n("span",{attrs:{class:"token comment"}},[t._v("// 新旧节点均存在，但节点类型发生改变")]),t._v("\n  "),n("span",{attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),n("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{attrs:{class:"token function"}},[t._v("isChanged")]),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" oldNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    $parent"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{attrs:{class:"token function"}},[t._v("replaceChild")]),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      "),n("span",{attrs:{class:"token function"}},[t._v("createElement")]),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      $parent"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("childNodes"),n("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("index"),n("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{attrs:{class:"token function"}},[t._v("isChanged")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node1"),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node2"),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{attrs:{class:"token keyword"}},[t._v("typeof")]),t._v(" node1 "),n("span",{attrs:{class:"token operator"}},[t._v("!==")]),t._v(" "),n("span",{attrs:{class:"token keyword"}},[t._v("typeof")]),t._v(" node2"),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{attrs:{class:"token operator"}},[t._v("||")]),t._v("\n    "),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{attrs:{class:"token keyword"}},[t._v("typeof")]),t._v(" node1 "),n("span",{attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),n("span",{attrs:{class:"token string"}},[t._v("'string'")]),t._v(" "),n("span",{attrs:{class:"token operator"}},[t._v("&&")]),t._v(" node1 "),n("span",{attrs:{class:"token operator"}},[t._v("!==")]),t._v(" node2"),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{attrs:{class:"token operator"}},[t._v("||")]),t._v("\n    "),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node1"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type "),n("span",{attrs:{class:"token operator"}},[t._v("!==")]),t._v(" node2"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type"),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),n("h4",{attrs:{id:"新旧节点均存在，且节点类型不变"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#新旧节点均存在，且节点类型不变","aria-hidden":"true"}},[t._v("#")]),t._v(" 新旧节点均存在，且节点类型不变")]),n("p",[t._v("原有节点是 div ，下面有 三个 span 子元素，现在节点也是 div ，下面有 四个 span 子元素。这时候我们取最大的长度，然后依次的进行判断和更新。")]),n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{attrs:{class:"token function"}},[t._v("updateElement")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("$parent"),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" newNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" oldNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" index "),n("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{attrs:{class:"token number"}},[t._v("0")]),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{attrs:{class:"token comment"}},[t._v("// …")]),t._v("\n  "),n("span",{attrs:{class:"token comment"}},[t._v("// 新旧节点类型相同")]),t._v("\n  "),n("span",{attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),n("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type"),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{attrs:{class:"token keyword"}},[t._v("const")]),t._v(" newLen "),n("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" Math"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{attrs:{class:"token function"}},[t._v("max")]),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      newNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("children"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length"),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      oldNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("children"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length\n    "),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{attrs:{class:"token keyword"}},[t._v("let")]),t._v(" i "),n("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{attrs:{class:"token number"}},[t._v("0")]),n("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i "),n("span",{attrs:{class:"token operator"}},[t._v("<")]),t._v(" newLen"),n("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i"),n("span",{attrs:{class:"token operator"}},[t._v("++")]),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),n("span",{attrs:{class:"token function"}},[t._v("updateElement")]),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n        $parent"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("childNodes"),n("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("index"),n("span",{attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        newNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("children"),n("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),n("span",{attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        oldNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("children"),n("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),n("span",{attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        i\n      "),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),n("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),n("h4",{attrs:{id:"完整的更新函数"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#完整的更新函数","aria-hidden":"true"}},[t._v("#")]),t._v(" 完整的更新函数")]),n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{attrs:{class:"token function"}},[t._v("isChanged")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node1"),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node2"),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{attrs:{class:"token keyword"}},[t._v("typeof")]),t._v(" node1 "),n("span",{attrs:{class:"token operator"}},[t._v("!==")]),t._v(" "),n("span",{attrs:{class:"token keyword"}},[t._v("typeof")]),t._v(" node2"),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{attrs:{class:"token operator"}},[t._v("||")]),t._v("\n    "),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{attrs:{class:"token keyword"}},[t._v("typeof")]),t._v(" node1 "),n("span",{attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),n("span",{attrs:{class:"token string"}},[t._v("'string'")]),t._v(" "),n("span",{attrs:{class:"token operator"}},[t._v("&&")]),t._v(" node1 "),n("span",{attrs:{class:"token operator"}},[t._v("!==")]),t._v(" node2"),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{attrs:{class:"token operator"}},[t._v("||")]),t._v("\n    "),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node1"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type "),n("span",{attrs:{class:"token operator"}},[t._v("!==")]),t._v(" node2"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type"),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{attrs:{class:"token function"}},[t._v("updateElement")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("$parent"),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" newNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" oldNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" index "),n("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{attrs:{class:"token number"}},[t._v("0")]),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{attrs:{class:"token operator"}},[t._v("!")]),t._v("oldNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    $parent"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{attrs:{class:"token function"}},[t._v("appendChild")]),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      "),n("span",{attrs:{class:"token function"}},[t._v("createElement")]),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),n("span",{attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),n("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{attrs:{class:"token operator"}},[t._v("!")]),t._v("newNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    $parent"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{attrs:{class:"token function"}},[t._v("removeChild")]),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      $parent"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("childNodes"),n("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("index"),n("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),n("span",{attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),n("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{attrs:{class:"token function"}},[t._v("isChanged")]),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" oldNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    $parent"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{attrs:{class:"token function"}},[t._v("replaceChild")]),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      "),n("span",{attrs:{class:"token function"}},[t._v("createElement")]),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      $parent"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("childNodes"),n("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("index"),n("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),n("span",{attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),n("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type"),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{attrs:{class:"token keyword"}},[t._v("const")]),t._v(" newLen "),n("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" Math"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{attrs:{class:"token function"}},[t._v("max")]),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      newNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("children"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length"),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      oldNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("children"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length\n    "),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{attrs:{class:"token keyword"}},[t._v("let")]),t._v(" i "),n("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{attrs:{class:"token number"}},[t._v("0")]),n("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i "),n("span",{attrs:{class:"token operator"}},[t._v("<")]),t._v(" newLen"),n("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i"),n("span",{attrs:{class:"token operator"}},[t._v("++")]),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),n("span",{attrs:{class:"token function"}},[t._v("updateElement")]),n("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n        $parent"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("childNodes"),n("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("index"),n("span",{attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        newNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("children"),n("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),n("span",{attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        oldNode"),n("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("children"),n("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),n("span",{attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        i\n      "),n("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),n("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])}],!1,null,null,null);s.default=o.exports}}]);